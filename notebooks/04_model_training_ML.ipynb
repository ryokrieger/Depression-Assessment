{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7df389",
   "metadata": {},
   "source": [
    "# Model Training (Machine Learning)\n",
    "\n",
    "We train six traditional ML classifiers on nine feature-selection datasets:\n",
    "\n",
    "1. **Recursive Feature Elimination**\n",
    "2. **Select K Best**\n",
    "3. **Fisher Score Chi-Square**\n",
    "4. **Extra Trees Classifier**\n",
    "5. **Pearson Correlation**\n",
    "6. **Mutual Information**\n",
    "7. **Mutual Info Regression**\n",
    "8. **Manual Uniqueness**\n",
    "9. **Variance Threshold**\n",
    "\n",
    "Each dataset trains:\n",
    "- Logistic Regression  \n",
    "- Gradient Boosting Classifier  \n",
    "- K-Nearest Neighbours  \n",
    "- Random Forest Classifier  \n",
    "- Decision Tree Classifier  \n",
    "- Support Vector Machine  \n",
    "\n",
    "Metrics → `Accuracy`, `Precision`, `Recall`, `F1`  \n",
    "Visuals → Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c1edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "FEATURES_BASE = Path(\"../data/processed/features\")\n",
    "PROC_BASE = Path(\"../data/processed/ml\")\n",
    "MODEL_BASE = Path(\"../models/ml\")\n",
    "FIG_BASE = Path(\"../figures/ml\")\n",
    "\n",
    "for p in [PROC_BASE, MODEL_BASE, FIG_BASE]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METHODS = [\"rfe\",\"skb\",\"fscs\",\"etc\",\"pc\",\"mi\",\"mir\",\"mu\",\"vt\"]\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba050ef",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_confusion(y_true, y_pred, path, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(title)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c8264",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55f7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155af3e1",
   "metadata": {},
   "source": [
    "## Train All Six Models Across Nine Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0ac10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Training ML models for: RFE\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for RFE to ..\\data\\processed\\ml\\rfe\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: SKB\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for SKB to ..\\data\\processed\\ml\\skb\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: FSCS\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for FSCS to ..\\data\\processed\\ml\\fscs\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: ETC\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for ETC to ..\\data\\processed\\ml\\etc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: PC\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for PC to ..\\data\\processed\\ml\\pc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: MI\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for MI to ..\\data\\processed\\ml\\mi\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: MIR\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for MIR to ..\\data\\processed\\ml\\mir\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: MU\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for MU to ..\\data\\processed\\ml\\mu\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for: VT\n",
      "============================================================\n",
      " - Training Logistic Regression ...\n",
      " - Training Gradient Boosting ...\n",
      " - Training KNN ...\n",
      " - Training Random Forest ...\n",
      " - Training Decision Tree ...\n",
      " - Training SVM ...\n",
      "✅ Saved results for VT to ..\\data\\processed\\ml\\vt\\results_traditional_ml.csv\n"
     ]
    }
   ],
   "source": [
    "for method in METHODS:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"▶ Training ML models for: {method.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    in_dir = FEATURES_BASE / method\n",
    "    train_path = in_dir / \"train.csv\"\n",
    "    test_path = in_dir / \"test.csv\"\n",
    "    if not train_path.exists() or not test_path.exists():\n",
    "        print(f\"⚠️ Missing train/test for {method}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    # clean / dtype\n",
    "    train_df = train_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "    test_df = test_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_train = train_df[\"DepressionEncoded\"].astype(int)\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_test = test_df[\"DepressionEncoded\"].astype(int)\n",
    "\n",
    "    results = []\n",
    "    # create method-specific folders\n",
    "    proc_out = PROC_BASE / method\n",
    "    model_out = MODEL_BASE / method\n",
    "    fig_out = FIG_BASE / method\n",
    "    for p in [proc_out, model_out, fig_out]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for name, model in MODELS.items():\n",
    "        print(f\" - Training {name} ...\")\n",
    "        # fit\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        metrics = compute_metrics(y_test, y_pred)\n",
    "        metrics_row = {\"Model\": name, **metrics}\n",
    "        results.append(metrics_row)\n",
    "\n",
    "        # save confusion matrix\n",
    "        cm_path = fig_out / f\"{name.lower().replace(' ', '_')}_confusion.png\"\n",
    "        plot_and_save_confusion(y_test, y_pred, cm_path, f\"{name} Confusion ({method.upper()})\")\n",
    "\n",
    "        # save model\n",
    "        model_path = model_out / f\"{name.lower().replace(' ', '_')}.pkl\"\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "    # save results CSV\n",
    "    res_df = pd.DataFrame(results)\n",
    "    res_df.to_csv(proc_out / \"results_traditional_ml.csv\", index=False)\n",
    "    print(f\"✅ Saved results for {method.upper()} to {proc_out / 'results_traditional_ml.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a2308",
   "metadata": {},
   "source": [
    "## Summary of Model Performance Across All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207b3fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Feature Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798754</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798470</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.790873</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789303</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.767866</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.766305</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.753958</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.749150</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.698765</td>\n",
       "      <td>0.700839</td>\n",
       "      <td>0.698765</td>\n",
       "      <td>0.695469</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.651852</td>\n",
       "      <td>0.662598</td>\n",
       "      <td>0.651852</td>\n",
       "      <td>0.653123</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.771709</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.768826</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.766566</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.761301</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.764876</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.761422</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.746842</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.738511</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.664598</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.659036</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.656790</td>\n",
       "      <td>0.657777</td>\n",
       "      <td>0.656790</td>\n",
       "      <td>0.655081</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.787616</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.785772</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.765043</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.763226</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733640</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.732153</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.732237</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.729158</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.706962</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.699541</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.596493</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.597870</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.769754</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.769848</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.754004</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.753378</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.747680</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.747034</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.745410</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.745117</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.695004</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.686164</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.679782</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.679199</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.732438</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.729139</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.728252</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.724362</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.720988</td>\n",
       "      <td>0.726588</td>\n",
       "      <td>0.720988</td>\n",
       "      <td>0.722110</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.707164</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.706175</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.651852</td>\n",
       "      <td>0.658630</td>\n",
       "      <td>0.651852</td>\n",
       "      <td>0.653909</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>0.646249</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>0.638787</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.791502</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789015</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.776476</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.775401</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.739811</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.739143</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.734118</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733124</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666621</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.660088</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>0.614370</td>\n",
       "      <td>0.612346</td>\n",
       "      <td>0.609048</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.788627</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.787144</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.777982</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.774717</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.757006</td>\n",
       "      <td>0.753086</td>\n",
       "      <td>0.751862</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.739327</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.735712</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.720909</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.715515</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.676543</td>\n",
       "      <td>0.678381</td>\n",
       "      <td>0.676543</td>\n",
       "      <td>0.674619</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.791502</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789015</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.776476</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.775401</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.742329</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.741473</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.732457</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.730846</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666621</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.660088</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.607407</td>\n",
       "      <td>0.608142</td>\n",
       "      <td>0.607407</td>\n",
       "      <td>0.606039</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.805098</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.804128</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.798466</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.796489</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.770838</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.769376</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.731416</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.730081</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.678672</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.671184</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>0.648039</td>\n",
       "      <td>0.641975</td>\n",
       "      <td>0.644072</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall        F1 Feature Set\n",
       "18  Logistic Regression  0.800000   0.798754  0.800000  0.798470         ETC\n",
       "23                  SVM  0.790123   0.790873  0.790123  0.789303         ETC\n",
       "19    Gradient Boosting  0.765432   0.767866  0.765432  0.766305         ETC\n",
       "21        Random Forest  0.750617   0.753958  0.750617  0.749150         ETC\n",
       "20                  KNN  0.698765   0.700839  0.698765  0.695469         ETC\n",
       "22        Decision Tree  0.651852   0.662598  0.651852  0.653123         ETC\n",
       "12  Logistic Regression  0.767901   0.771709  0.767901  0.768826        FSCS\n",
       "13    Gradient Boosting  0.760494   0.766566  0.760494  0.761301        FSCS\n",
       "17                  SVM  0.760494   0.764876  0.760494  0.761422        FSCS\n",
       "15        Random Forest  0.738272   0.746842  0.738272  0.738511        FSCS\n",
       "14                  KNN  0.661728   0.664598  0.661728  0.659036        FSCS\n",
       "16        Decision Tree  0.656790   0.657777  0.656790  0.655081        FSCS\n",
       "30  Logistic Regression  0.787654   0.787616  0.787654  0.785772          MI\n",
       "35                  SVM  0.762963   0.765043  0.762963  0.763226          MI\n",
       "31    Gradient Boosting  0.733333   0.733640  0.733333  0.732153          MI\n",
       "33        Random Forest  0.728395   0.732237  0.728395  0.729158          MI\n",
       "32                  KNN  0.706173   0.706962  0.706173  0.699541          MI\n",
       "34        Decision Tree  0.600000   0.596493  0.600000  0.597870          MI\n",
       "36  Logistic Regression  0.770370   0.769754  0.770370  0.769848         MIR\n",
       "39        Random Forest  0.753086   0.754004  0.753086  0.753378         MIR\n",
       "37    Gradient Boosting  0.748148   0.747680  0.748148  0.747034         MIR\n",
       "41                  SVM  0.745679   0.745410  0.745679  0.745117         MIR\n",
       "38                  KNN  0.691358   0.695004  0.691358  0.686164         MIR\n",
       "40        Decision Tree  0.679012   0.679782  0.679012  0.679199         MIR\n",
       "42  Logistic Regression  0.728395   0.732438  0.728395  0.729139          MU\n",
       "47                  SVM  0.723457   0.728252  0.723457  0.724362          MU\n",
       "45        Random Forest  0.720988   0.726588  0.720988  0.722110          MU\n",
       "43    Gradient Boosting  0.706173   0.707164  0.706173  0.706175          MU\n",
       "46        Decision Tree  0.651852   0.658630  0.651852  0.653909          MU\n",
       "44                  KNN  0.639506   0.646249  0.639506  0.638787          MU\n",
       "24  Logistic Regression  0.790123   0.791502  0.790123  0.789015          PC\n",
       "29                  SVM  0.775309   0.776476  0.775309  0.775401          PC\n",
       "25    Gradient Boosting  0.740741   0.739811  0.740741  0.739143          PC\n",
       "27        Random Forest  0.733333   0.734118  0.733333  0.733124          PC\n",
       "26                  KNN  0.666667   0.666621  0.666667  0.660088          PC\n",
       "28        Decision Tree  0.612346   0.614370  0.612346  0.609048          PC\n",
       "0   Logistic Regression  0.787654   0.788627  0.787654  0.787144         RFE\n",
       "5                   SVM  0.775309   0.777982  0.775309  0.774717         RFE\n",
       "3         Random Forest  0.753086   0.757006  0.753086  0.751862         RFE\n",
       "1     Gradient Boosting  0.735802   0.739327  0.735802  0.735712         RFE\n",
       "2                   KNN  0.718519   0.720909  0.718519  0.715515         RFE\n",
       "4         Decision Tree  0.676543   0.678381  0.676543  0.674619         RFE\n",
       "6   Logistic Regression  0.790123   0.791502  0.790123  0.789015         SKB\n",
       "11                  SVM  0.775309   0.776476  0.775309  0.775401         SKB\n",
       "7     Gradient Boosting  0.743210   0.742329  0.743210  0.741473         SKB\n",
       "9         Random Forest  0.730864   0.732457  0.730864  0.730846         SKB\n",
       "8                   KNN  0.666667   0.666621  0.666667  0.660088         SKB\n",
       "10        Decision Tree  0.607407   0.608142  0.607407  0.606039         SKB\n",
       "48  Logistic Regression  0.804938   0.805098  0.804938  0.804128          VT\n",
       "53                  SVM  0.797531   0.798466  0.797531  0.796489          VT\n",
       "49    Gradient Boosting  0.770370   0.770838  0.770370  0.769376          VT\n",
       "51        Random Forest  0.730864   0.731416  0.730864  0.730081          VT\n",
       "50                  KNN  0.679012   0.678672  0.679012  0.671184          VT\n",
       "52        Decision Tree  0.641975   0.648039  0.641975  0.644072          VT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined model summary saved → ..\\data\\processed\\ml\\all_model_results_summary.csv\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for method in METHODS:\n",
    "    res_path = PROC_BASE / method / \"results_traditional_ml.csv\"\n",
    "    if res_path.exists():\n",
    "        df = pd.read_csv(res_path)\n",
    "        df[\"Feature Set\"] = method.upper()\n",
    "        all_results.append(df)\n",
    "    else:\n",
    "        print(f\"⚠️ Missing results for {method.upper()}\")\n",
    "\n",
    "if all_results:\n",
    "    combined_results = pd.concat(all_results, ignore_index=True)\n",
    "    combined_results = combined_results.sort_values([\"Feature Set\", \"Accuracy\"], ascending=[True, False])\n",
    "    \n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    display(combined_results)\n",
    "\n",
    "    # Save the full summary for documentation\n",
    "    summary_out = PROC_BASE / \"all_model_results_summary.csv\"\n",
    "    combined_results.to_csv(summary_out, index=False)\n",
    "    print(f\"✅ Combined model summary saved → {summary_out}\")\n",
    "else:\n",
    "    print(\"⚠️ No model results found. Please run training first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
