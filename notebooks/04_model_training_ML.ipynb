{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7df389",
   "metadata": {},
   "source": [
    "# Model Training (Machine Learning)\n",
    "\n",
    "We train six traditional ML classifiers on nine feature-selection datasets:\n",
    "\n",
    "1. **Recursive Feature Elimination**\n",
    "2. **Select K Best**\n",
    "3. **Fisher Score Chi-Square**\n",
    "4. **Extra Trees Classifier**\n",
    "5. **Pearson Correlation**\n",
    "6. **Mutual Information**\n",
    "7. **Mutual Info Regression**\n",
    "8. **Manual Uniqueness**\n",
    "9. **Variance Threshold**\n",
    "\n",
    "Each dataset trains:\n",
    "- Logistic Regression  \n",
    "- Gradient Boosting Classifier  \n",
    "- K-Nearest Neighbours  \n",
    "- Random Forest Classifier  \n",
    "- Decision Tree Classifier  \n",
    "- Support Vector Machine  \n",
    "\n",
    "Metrics ‚Üí `Accuracy`, `Precision`, `Recall`, `F1`  \n",
    "Visuals ‚Üí Confusion Matrices  \n",
    "Results, Models and Figures are saved in respective folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c1edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed/features\")\n",
    "PROC_DIR = Path(\"../data/processed/ml\")\n",
    "MODEL_DIR_BASE = Path(\"../models/ml\")\n",
    "FIG_DIR_BASE = Path(\"../figures/ml\")\n",
    "\n",
    "METHODS = [\"rfe\",\"skb\",\"fscs\",\"etc\",\"pc\",\"mi\",\"mir\",\"mu\",\"vt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba050ef",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "These utilities:\n",
    "- Train each model  \n",
    "- Compute metrics (Accuracy, Precision, Recall, F1)  \n",
    "- Plot and save Confusion Matrices  \n",
    "- Save trained models and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name, method):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_title(f\"{model_name} ‚Äî {method.upper()}\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig_dir = FIG_DIR_BASE / method\n",
    "    fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fig_path = fig_dir / f\"{model_name.lower().replace(' ', '_')}_confusion.png\"\n",
    "    fig.savefig(fig_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    return {\"Model\": model_name, \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1}\n",
    "\n",
    "\n",
    "def save_model(model, model_name, method):\n",
    "    model_dir = MODEL_DIR_BASE / method\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    path = model_dir / f\"{model_name.lower().replace(' ', '_')}.pkl\"\n",
    "    joblib.dump(model, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c8264",
   "metadata": {},
   "source": [
    "## Model Definitions\n",
    "\n",
    "We define six traditional ML models to train on each feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55f7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155af3e1",
   "metadata": {},
   "source": [
    "## Train All Six Models Across Nine Feature Sets\n",
    "\n",
    "For each feature-selection method:\n",
    "1. Load train/test CSV files  \n",
    "2. Train six models  \n",
    "3. Compute metrics and save results + models + confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0ac10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training models for RFE ===\n",
      "üß† Training Logistic Regression\n",
      "üß† Training Gradient Boosting\n",
      "üß† Training KNN\n",
      "üß† Training Random Forest\n",
      "üß† Training Decision Tree\n",
      "üß† Training SVM\n",
      "‚úÖ Saved metrics ‚Üí ..\\data\\processed\\ml\\rfe\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for SKB ===\n",
      "üß† Training Logistic Regression\n",
      "üß† Training Gradient Boosting\n",
      "üß† Training KNN\n",
      "üß† Training Random Forest\n",
      "üß† Training Decision Tree\n",
      "üß† Training SVM\n",
      "‚úÖ Saved metrics ‚Üí ..\\data\\processed\\ml\\skb\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for FSCS ===\n",
      "üß† Training Logistic Regression\n",
      "üß† Training Gradient Boosting\n",
      "üß† Training KNN\n",
      "üß† Training Random Forest\n",
      "üß† Training Decision Tree\n",
      "üß† Training SVM\n",
      "‚úÖ Saved metrics ‚Üí ..\\data\\processed\\ml\\fscs\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for ETC ===\n",
      "üß† Training Logistic Regression\n",
      "üß† Training Gradient Boosting\n",
      "üß† Training KNN\n",
      "üß† Training Random Forest\n",
      "üß† Training Decision Tree\n",
      "üß† Training SVM\n",
      "‚úÖ Saved metrics ‚Üí ..\\data\\processed\\ml\\etc\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for PC ===\n",
      "üß† Training Logistic Regression\n",
      "üß† Training Gradient Boosting\n",
      "üß† Training KNN\n",
      "üß† Training Random Forest\n",
      "üß† Training Decision Tree\n",
      "üß† Training SVM\n",
      "‚úÖ Saved metrics ‚Üí ..\\data\\processed\\ml\\pc\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for MI ===\n",
      "üß† Training Logistic Regression\n",
      "üß† Training Gradient Boosting\n",
      "üß† Training KNN\n",
      "üß† Training Random Forest\n",
      "üß† Training Decision Tree\n",
      "üß† Training SVM\n",
      "‚úÖ Saved metrics ‚Üí ..\\data\\processed\\ml\\mi\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for MIR ===\n",
      "üß† Training Logistic Regression\n",
      "üß† Training Gradient Boosting\n",
      "üß† Training KNN\n",
      "üß† Training Random Forest\n",
      "üß† Training Decision Tree\n",
      "üß† Training SVM\n",
      "‚úÖ Saved metrics ‚Üí ..\\data\\processed\\ml\\mir\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for MU ===\n",
      "üß† Training Logistic Regression\n",
      "üß† Training Gradient Boosting\n",
      "üß† Training KNN\n",
      "üß† Training Random Forest\n",
      "üß† Training Decision Tree\n",
      "üß† Training SVM\n",
      "‚úÖ Saved metrics ‚Üí ..\\data\\processed\\ml\\mu\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for VT ===\n",
      "üß† Training Logistic Regression\n",
      "üß† Training Gradient Boosting\n",
      "üß† Training KNN\n",
      "üß† Training Random Forest\n",
      "üß† Training Decision Tree\n",
      "üß† Training SVM\n",
      "‚úÖ Saved metrics ‚Üí ..\\data\\processed\\ml\\vt\\results_traditional_ml.csv\n"
     ]
    }
   ],
   "source": [
    "for method in METHODS:\n",
    "    print(f\"\\n=== Training models for {method.upper()} ===\")\n",
    "\n",
    "    train_path = DATA_DIR / method / \"train.csv\"\n",
    "    test_path = DATA_DIR / method / \"test.csv\"\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    # Drop any missing rows\n",
    "    train_df = train_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "    test_df = test_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_train = train_df[\"DepressionEncoded\"].astype(int)\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_test = test_df[\"DepressionEncoded\"].astype(int)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, model in MODELS.items():\n",
    "        print(f\"üß† Training {name}\")\n",
    "        metrics = train_and_evaluate(model, X_train, y_train, X_test, y_test, name, method)\n",
    "        results.append(metrics)\n",
    "        save_model(model, name, method)\n",
    "\n",
    "    res_df = pd.DataFrame(results)\n",
    "    out_dir = PROC_DIR / method\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    res_df.to_csv(out_dir / \"results_traditional_ml.csv\", index=False)\n",
    "\n",
    "    print(f\"‚úÖ Saved metrics ‚Üí {out_dir / 'results_traditional_ml.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a2308",
   "metadata": {},
   "source": [
    "## üßÆ Summary of Model Performance Across All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207b3fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Feature Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798754</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798470</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.790873</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789303</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.767866</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.766305</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.755275</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.751077</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.698765</td>\n",
       "      <td>0.700839</td>\n",
       "      <td>0.698765</td>\n",
       "      <td>0.695469</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.649383</td>\n",
       "      <td>0.658683</td>\n",
       "      <td>0.649383</td>\n",
       "      <td>0.649530</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.771709</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.768826</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.770586</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.764045</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.766566</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.761301</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.764876</td>\n",
       "      <td>0.760494</td>\n",
       "      <td>0.761422</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.664598</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.659036</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.662358</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.660362</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.787616</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.785772</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.765043</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.763226</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.740618</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.738701</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.733640</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.732153</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.706962</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.699541</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.597531</td>\n",
       "      <td>0.596443</td>\n",
       "      <td>0.597531</td>\n",
       "      <td>0.596448</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.769754</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.769848</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.747680</td>\n",
       "      <td>0.748148</td>\n",
       "      <td>0.747034</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.745410</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.745117</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.742570</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.742363</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.695004</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.686164</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.665784</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.665860</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.732438</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.729139</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.732367</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.729273</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.728252</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.724362</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.707164</td>\n",
       "      <td>0.706173</td>\n",
       "      <td>0.706175</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.663795</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.661818</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>0.646249</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>0.638787</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.791502</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789015</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.776476</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.775401</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.742329</td>\n",
       "      <td>0.743210</td>\n",
       "      <td>0.741473</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.725926</td>\n",
       "      <td>0.730227</td>\n",
       "      <td>0.725926</td>\n",
       "      <td>0.727050</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666621</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.660088</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.598891</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.597528</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.788627</td>\n",
       "      <td>0.787654</td>\n",
       "      <td>0.787144</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.777982</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.774717</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>0.778219</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>0.774412</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.739327</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.735712</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.720909</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.715515</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.668061</td>\n",
       "      <td>0.661728</td>\n",
       "      <td>0.660619</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.791502</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789015</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.776476</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.775401</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.739811</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.739143</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.743426</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.741306</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666621</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.660088</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.609877</td>\n",
       "      <td>0.609564</td>\n",
       "      <td>0.609877</td>\n",
       "      <td>0.607677</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.805098</td>\n",
       "      <td>0.804938</td>\n",
       "      <td>0.804128</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.798466</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.796489</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.770838</td>\n",
       "      <td>0.770370</td>\n",
       "      <td>0.769376</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.738507</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.735672</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.678672</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.671184</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.632902</td>\n",
       "      <td>0.622222</td>\n",
       "      <td>0.625790</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall        F1 Feature Set\n",
       "18  Logistic Regression  0.800000   0.798754  0.800000  0.798470         ETC\n",
       "23                  SVM  0.790123   0.790873  0.790123  0.789303         ETC\n",
       "19    Gradient Boosting  0.765432   0.767866  0.765432  0.766305         ETC\n",
       "21        Random Forest  0.750617   0.755275  0.750617  0.751077         ETC\n",
       "20                  KNN  0.698765   0.700839  0.698765  0.695469         ETC\n",
       "22        Decision Tree  0.649383   0.658683  0.649383  0.649530         ETC\n",
       "12  Logistic Regression  0.767901   0.771709  0.767901  0.768826        FSCS\n",
       "15        Random Forest  0.762963   0.770586  0.762963  0.764045        FSCS\n",
       "13    Gradient Boosting  0.760494   0.766566  0.760494  0.761301        FSCS\n",
       "17                  SVM  0.760494   0.764876  0.760494  0.761422        FSCS\n",
       "14                  KNN  0.661728   0.664598  0.661728  0.659036        FSCS\n",
       "16        Decision Tree  0.661728   0.662358  0.661728  0.660362        FSCS\n",
       "30  Logistic Regression  0.787654   0.787616  0.787654  0.785772          MI\n",
       "35                  SVM  0.762963   0.765043  0.762963  0.763226          MI\n",
       "33        Random Forest  0.738272   0.740618  0.738272  0.738701          MI\n",
       "31    Gradient Boosting  0.733333   0.733640  0.733333  0.732153          MI\n",
       "32                  KNN  0.706173   0.706962  0.706173  0.699541          MI\n",
       "34        Decision Tree  0.597531   0.596443  0.597531  0.596448          MI\n",
       "36  Logistic Regression  0.770370   0.769754  0.770370  0.769848         MIR\n",
       "37    Gradient Boosting  0.748148   0.747680  0.748148  0.747034         MIR\n",
       "41                  SVM  0.745679   0.745410  0.745679  0.745117         MIR\n",
       "39        Random Forest  0.743210   0.742570  0.743210  0.742363         MIR\n",
       "38                  KNN  0.691358   0.695004  0.691358  0.686164         MIR\n",
       "40        Decision Tree  0.666667   0.665784  0.666667  0.665860         MIR\n",
       "42  Logistic Regression  0.728395   0.732438  0.728395  0.729139          MU\n",
       "45        Random Forest  0.728395   0.732367  0.728395  0.729273          MU\n",
       "47                  SVM  0.723457   0.728252  0.723457  0.724362          MU\n",
       "43    Gradient Boosting  0.706173   0.707164  0.706173  0.706175          MU\n",
       "46        Decision Tree  0.661728   0.663795  0.661728  0.661818          MU\n",
       "44                  KNN  0.639506   0.646249  0.639506  0.638787          MU\n",
       "24  Logistic Regression  0.790123   0.791502  0.790123  0.789015          PC\n",
       "29                  SVM  0.775309   0.776476  0.775309  0.775401          PC\n",
       "25    Gradient Boosting  0.743210   0.742329  0.743210  0.741473          PC\n",
       "27        Random Forest  0.725926   0.730227  0.725926  0.727050          PC\n",
       "26                  KNN  0.666667   0.666621  0.666667  0.660088          PC\n",
       "28        Decision Tree  0.600000   0.598891  0.600000  0.597528          PC\n",
       "0   Logistic Regression  0.787654   0.788627  0.787654  0.787144         RFE\n",
       "5                   SVM  0.775309   0.777982  0.775309  0.774717         RFE\n",
       "3         Random Forest  0.772840   0.778219  0.772840  0.774412         RFE\n",
       "1     Gradient Boosting  0.735802   0.739327  0.735802  0.735712         RFE\n",
       "2                   KNN  0.718519   0.720909  0.718519  0.715515         RFE\n",
       "4         Decision Tree  0.661728   0.668061  0.661728  0.660619         RFE\n",
       "6   Logistic Regression  0.790123   0.791502  0.790123  0.789015         SKB\n",
       "11                  SVM  0.775309   0.776476  0.775309  0.775401         SKB\n",
       "7     Gradient Boosting  0.740741   0.739811  0.740741  0.739143         SKB\n",
       "9         Random Forest  0.740741   0.743426  0.740741  0.741306         SKB\n",
       "8                   KNN  0.666667   0.666621  0.666667  0.660088         SKB\n",
       "10        Decision Tree  0.609877   0.609564  0.609877  0.607677         SKB\n",
       "48  Logistic Regression  0.804938   0.805098  0.804938  0.804128          VT\n",
       "53                  SVM  0.797531   0.798466  0.797531  0.796489          VT\n",
       "49    Gradient Boosting  0.770370   0.770838  0.770370  0.769376          VT\n",
       "51        Random Forest  0.735802   0.738507  0.735802  0.735672          VT\n",
       "50                  KNN  0.679012   0.678672  0.679012  0.671184          VT\n",
       "52        Decision Tree  0.622222   0.632902  0.622222  0.625790          VT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Combined model summary saved ‚Üí ..\\data\\processed\\ml\\all_model_results_summary.csv\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for method in METHODS:\n",
    "    res_path = PROC_DIR / method / \"results_traditional_ml.csv\"\n",
    "    if res_path.exists():\n",
    "        df = pd.read_csv(res_path)\n",
    "        df[\"Feature Set\"] = method.upper()\n",
    "        all_results.append(df)\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Missing results for {method.upper()}\")\n",
    "\n",
    "if all_results:\n",
    "    combined_results = pd.concat(all_results, ignore_index=True)\n",
    "    combined_results = combined_results.sort_values([\"Feature Set\", \"Accuracy\"], ascending=[True, False])\n",
    "    \n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    display(combined_results)\n",
    "\n",
    "    # Save the full summary for documentation\n",
    "    summary_out = PROC_DIR / \"all_model_results_summary.csv\"\n",
    "    combined_results.to_csv(summary_out, index=False)\n",
    "    print(f\"‚úÖ Combined model summary saved ‚Üí {summary_out}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No model results found. Please run training first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
