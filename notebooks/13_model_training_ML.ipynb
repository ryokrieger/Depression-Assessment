{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7df389",
   "metadata": {},
   "source": [
    "# Model Training (Machine Learning)\n",
    "\n",
    "We train six traditional ML classifiers on nine feature-selection datasets:\n",
    "\n",
    "1. **Recursive Feature Elimination**\n",
    "2. **Select K Best**\n",
    "3. **Fisher Score Chi-Square**\n",
    "4. **Extra Trees Classifier**\n",
    "5. **Pearson Correlation**\n",
    "6. **Mutual Information**\n",
    "7. **Mutual Info Regression**\n",
    "8. **Manual Uniqueness**\n",
    "9. **Variance Threshold**\n",
    "\n",
    "Each dataset trains:\n",
    "- Logistic Regression  \n",
    "- Gradient Boosting Classifier  \n",
    "- K-Nearest Neighbours  \n",
    "- Random Forest Classifier  \n",
    "- Decision Tree Classifier  \n",
    "- Support Vector Machine  \n",
    "\n",
    "Metrics → `Accuracy`, `Precision`, `Recall`, `F1`  \n",
    "Visuals → Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c1edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "FEATURES_BASE = Path(\"../data/processed/features3\")\n",
    "PROC_BASE = Path(\"../data/processed/ml3\")\n",
    "MODEL_BASE = Path(\"../models/ml3\")\n",
    "FIG_BASE = Path(\"../figures/ml3\")\n",
    "\n",
    "for p in [PROC_BASE, MODEL_BASE, FIG_BASE]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METHODS = [\"rfe\",\"skb\",\"fscs\",\"etc\",\"pc\",\"mi\",\"mir\",\"mu\",\"vt\"]\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba050ef",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    }\n",
    "\n",
    "def save_confusion(y_true, y_pred, path, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\"); ax.set_title(title)\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c8264",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55f7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"SVM\": SVC(probability=True, random_state=RANDOM_STATE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155af3e1",
   "metadata": {},
   "source": [
    "## Train All Six Models Across Nine Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0ac10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: RFE\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\rfe\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: SKB\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\skb\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: FSCS\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\fscs\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: ETC\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\etc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: PC\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\pc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: MI\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\mi\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: MIR\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\mir\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: MU\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\mu\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "▶ Training ML models for feature set: VT\n",
      "============================================================\n",
      " - Training: Logistic Regression\n",
      " - Training: Gradient Boosting\n",
      " - Training: KNN\n",
      " - Training: Random Forest\n",
      " - Training: Decision Tree\n",
      " - Training: SVM\n",
      "✅ Saved metrics to: ..\\data\\processed\\ml3\\vt\\results_traditional_ml.csv\n"
     ]
    }
   ],
   "source": [
    "for method in METHODS:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"▶ Training ML models for feature set: {method.upper()}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    in_dir = FEATURES_BASE / method\n",
    "    train_path = in_dir / \"train.csv\"\n",
    "    test_path = in_dir / \"test.csv\"\n",
    "    if not train_path.exists() or not test_path.exists():\n",
    "        print(f\"⚠️ Missing train/test for {method}, skipping.\")\n",
    "        continue\n",
    "\n",
    "    train_df = pd.read_csv(train_path).dropna(subset=[\"DepressionEncoded\"])\n",
    "    test_df = pd.read_csv(test_path).dropna(subset=[\"DepressionEncoded\"])\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_train = train_df[\"DepressionEncoded\"].astype(int)\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_test = test_df[\"DepressionEncoded\"].astype(int)\n",
    "\n",
    "    results = []\n",
    "    proc_out = PROC_BASE / method; model_out = MODEL_BASE / method; fig_out = FIG_BASE / method\n",
    "    for p in [proc_out, model_out, fig_out]:\n",
    "        p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for name, model in MODELS.items():\n",
    "        print(f\" - Training: {name}\")\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        metrics = compute_metrics(y_test, y_pred)\n",
    "        results.append({\"Model\": name, **metrics})\n",
    "\n",
    "        # save confusion & model\n",
    "        save_confusion(y_test, y_pred, fig_out / f\"{name.lower().replace(' ', '_')}_confusion.png\", f\"{name} Confusion ({method.upper()})\")\n",
    "        joblib.dump(model, model_out / f\"{name.lower().replace(' ', '_')}.pkl\")\n",
    "\n",
    "    # save metrics CSV\n",
    "    pd.DataFrame(results).to_csv(proc_out / \"results_traditional_ml.csv\", index=False)\n",
    "    print(f\"✅ Saved metrics to: {proc_out / 'results_traditional_ml.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a2308",
   "metadata": {},
   "source": [
    "## Summary of Model Performance Across All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207b3fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Feature Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.814741</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.813889</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789645</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.788129</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.758570</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.756682</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.739972</td>\n",
       "      <td>0.735802</td>\n",
       "      <td>0.736517</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.689617</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.687916</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.686420</td>\n",
       "      <td>0.695373</td>\n",
       "      <td>0.686420</td>\n",
       "      <td>0.687845</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.771215</td>\n",
       "      <td>0.767901</td>\n",
       "      <td>0.768374</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.749539</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.746332</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.720988</td>\n",
       "      <td>0.722257</td>\n",
       "      <td>0.720988</td>\n",
       "      <td>0.720471</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.724473</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.719834</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.701235</td>\n",
       "      <td>0.699245</td>\n",
       "      <td>0.701235</td>\n",
       "      <td>0.697355</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.646914</td>\n",
       "      <td>0.648844</td>\n",
       "      <td>0.646914</td>\n",
       "      <td>0.647364</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797883</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.795648</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.752061</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.751181</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.740634</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.738149</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.722729</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.720241</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.663523</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.632099</td>\n",
       "      <td>0.635731</td>\n",
       "      <td>0.632099</td>\n",
       "      <td>0.631771</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.764381</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.764438</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.753943</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.754560</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.746305</td>\n",
       "      <td>0.745679</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.731387</td>\n",
       "      <td>0.730864</td>\n",
       "      <td>0.730439</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.713580</td>\n",
       "      <td>0.708930</td>\n",
       "      <td>0.713580</td>\n",
       "      <td>0.709558</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.693827</td>\n",
       "      <td>0.691169</td>\n",
       "      <td>0.693827</td>\n",
       "      <td>0.691222</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.731409</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.728517</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.725926</td>\n",
       "      <td>0.730026</td>\n",
       "      <td>0.725926</td>\n",
       "      <td>0.726755</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.713580</td>\n",
       "      <td>0.721068</td>\n",
       "      <td>0.713580</td>\n",
       "      <td>0.715086</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.693827</td>\n",
       "      <td>0.700379</td>\n",
       "      <td>0.693827</td>\n",
       "      <td>0.695024</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.684843</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.686049</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>0.645320</td>\n",
       "      <td>0.639506</td>\n",
       "      <td>0.639853</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797883</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.795648</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.752061</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.751181</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.740634</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.738149</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.721749</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.719801</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.663523</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.632099</td>\n",
       "      <td>0.635731</td>\n",
       "      <td>0.632099</td>\n",
       "      <td>0.631771</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.789293</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.788880</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>0.776255</td>\n",
       "      <td>0.772840</td>\n",
       "      <td>0.772747</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.758025</td>\n",
       "      <td>0.761833</td>\n",
       "      <td>0.758025</td>\n",
       "      <td>0.759272</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.744936</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.740935</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.718684</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.717544</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.693569</td>\n",
       "      <td>0.688889</td>\n",
       "      <td>0.689858</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.797883</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.795648</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.752061</td>\n",
       "      <td>0.750617</td>\n",
       "      <td>0.751181</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.740634</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.738149</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.713580</td>\n",
       "      <td>0.719640</td>\n",
       "      <td>0.713580</td>\n",
       "      <td>0.715903</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.663523</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.664549</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.632099</td>\n",
       "      <td>0.635731</td>\n",
       "      <td>0.632099</td>\n",
       "      <td>0.631771</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.812346</td>\n",
       "      <td>0.813312</td>\n",
       "      <td>0.812346</td>\n",
       "      <td>0.811300</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799838</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.798051</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.778063</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777599</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.757269</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.755402</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.731208</td>\n",
       "      <td>0.728395</td>\n",
       "      <td>0.729267</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.701235</td>\n",
       "      <td>0.710112</td>\n",
       "      <td>0.701235</td>\n",
       "      <td>0.704373</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall        F1 Feature Set\n",
       "18  Logistic Regression  0.814815   0.814741  0.814815  0.813889         ETC\n",
       "23                  SVM  0.790123   0.789645  0.790123  0.788129         ETC\n",
       "19    Gradient Boosting  0.755556   0.758570  0.755556  0.756682         ETC\n",
       "21        Random Forest  0.735802   0.739972  0.735802  0.736517         ETC\n",
       "20                  KNN  0.688889   0.689617  0.688889  0.687916         ETC\n",
       "22        Decision Tree  0.686420   0.695373  0.686420  0.687845         ETC\n",
       "12  Logistic Regression  0.767901   0.771215  0.767901  0.768374        FSCS\n",
       "17                  SVM  0.745679   0.749539  0.745679  0.746332        FSCS\n",
       "15        Random Forest  0.720988   0.722257  0.720988  0.720471        FSCS\n",
       "13    Gradient Boosting  0.718519   0.724473  0.718519  0.719834        FSCS\n",
       "14                  KNN  0.701235   0.699245  0.701235  0.697355        FSCS\n",
       "16        Decision Tree  0.646914   0.648844  0.646914  0.647364        FSCS\n",
       "30  Logistic Regression  0.797531   0.797883  0.797531  0.795648          MI\n",
       "35                  SVM  0.750617   0.752061  0.750617  0.751181          MI\n",
       "31    Gradient Boosting  0.738272   0.740634  0.738272  0.738149          MI\n",
       "33        Random Forest  0.718519   0.722729  0.718519  0.720241          MI\n",
       "32                  KNN  0.666667   0.663523  0.666667  0.664549          MI\n",
       "34        Decision Tree  0.632099   0.635731  0.632099  0.631771          MI\n",
       "36  Logistic Regression  0.765432   0.764381  0.765432  0.764438         MIR\n",
       "39        Random Forest  0.755556   0.753943  0.755556  0.754560         MIR\n",
       "41                  SVM  0.745679   0.746305  0.745679  0.745550         MIR\n",
       "37    Gradient Boosting  0.730864   0.731387  0.730864  0.730439         MIR\n",
       "38                  KNN  0.713580   0.708930  0.713580  0.709558         MIR\n",
       "40        Decision Tree  0.693827   0.691169  0.693827  0.691222         MIR\n",
       "42  Logistic Regression  0.728395   0.731409  0.728395  0.728517          MU\n",
       "47                  SVM  0.725926   0.730026  0.725926  0.726755          MU\n",
       "43    Gradient Boosting  0.713580   0.721068  0.713580  0.715086          MU\n",
       "45        Random Forest  0.693827   0.700379  0.693827  0.695024          MU\n",
       "44                  KNN  0.688889   0.684843  0.688889  0.686049          MU\n",
       "46        Decision Tree  0.639506   0.645320  0.639506  0.639853          MU\n",
       "24  Logistic Regression  0.797531   0.797883  0.797531  0.795648          PC\n",
       "29                  SVM  0.750617   0.752061  0.750617  0.751181          PC\n",
       "25    Gradient Boosting  0.738272   0.740634  0.738272  0.738149          PC\n",
       "27        Random Forest  0.718519   0.721749  0.718519  0.719801          PC\n",
       "26                  KNN  0.666667   0.663523  0.666667  0.664549          PC\n",
       "28        Decision Tree  0.632099   0.635731  0.632099  0.631771          PC\n",
       "0   Logistic Regression  0.790123   0.789293  0.790123  0.788880         RFE\n",
       "5                   SVM  0.772840   0.776255  0.772840  0.772747         RFE\n",
       "1     Gradient Boosting  0.758025   0.761833  0.758025  0.759272         RFE\n",
       "3         Random Forest  0.740741   0.744936  0.740741  0.740935         RFE\n",
       "2                   KNN  0.718519   0.718684  0.718519  0.717544         RFE\n",
       "4         Decision Tree  0.688889   0.693569  0.688889  0.689858         RFE\n",
       "6   Logistic Regression  0.797531   0.797883  0.797531  0.795648         SKB\n",
       "11                  SVM  0.750617   0.752061  0.750617  0.751181         SKB\n",
       "7     Gradient Boosting  0.738272   0.740634  0.738272  0.738149         SKB\n",
       "9         Random Forest  0.713580   0.719640  0.713580  0.715903         SKB\n",
       "8                   KNN  0.666667   0.663523  0.666667  0.664549         SKB\n",
       "10        Decision Tree  0.632099   0.635731  0.632099  0.631771         SKB\n",
       "48  Logistic Regression  0.812346   0.813312  0.812346  0.811300          VT\n",
       "53                  SVM  0.800000   0.799838  0.800000  0.798051          VT\n",
       "49    Gradient Boosting  0.777778   0.778063  0.777778  0.777599          VT\n",
       "51        Random Forest  0.755556   0.757269  0.755556  0.755402          VT\n",
       "50                  KNN  0.728395   0.731208  0.728395  0.729267          VT\n",
       "52        Decision Tree  0.701235   0.710112  0.701235  0.704373          VT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined model summary saved → ..\\data\\processed\\ml3\\all_model_results_summary_v4.csv\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "for method in METHODS:\n",
    "    res_path = PROC_BASE / method / \"results_traditional_ml.csv\"\n",
    "    if res_path.exists():\n",
    "        df = pd.read_csv(res_path)\n",
    "        df[\"Feature Set\"] = method.upper()\n",
    "        all_results.append(df)\n",
    "    else:\n",
    "        print(f\"⚠️ Missing results for {method.upper()}\")\n",
    "\n",
    "if all_results:\n",
    "    combined_results = pd.concat(all_results, ignore_index=True)\n",
    "    combined_results = combined_results.sort_values([\"Feature Set\", \"Accuracy\"], ascending=[True, False])\n",
    "    pd.set_option(\"display.max_rows\", None)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    display(combined_results)\n",
    "    summary_out = PROC_BASE / \"all_model_results_summary_v4.csv\"\n",
    "    combined_results.to_csv(summary_out, index=False)\n",
    "    print(f\"✅ Combined model summary saved → {summary_out}\")\n",
    "else:\n",
    "    print(\"⚠️ No model results found. Please run training first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
