{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7df389",
   "metadata": {},
   "source": [
    "# Model Training (Machine Learning)\n",
    "\n",
    "We train six traditional ML classifiers on nine feature-selection datasets:\n",
    "\n",
    "1. **Recursive Feature Elimination**\n",
    "2. **Select K Best**\n",
    "3. **Fisher Score Chi-Square**\n",
    "4. **Extra Trees Classifier**\n",
    "5. **Pearson Correlation**\n",
    "6. **Mutual Information**\n",
    "7. **Mutual Info Regression**\n",
    "8. **Manual Uniqueness**\n",
    "9. **Variance Threshold**\n",
    "\n",
    "Each dataset trains:\n",
    "- Logistic Regression  \n",
    "- Gradient Boosting Classifier  \n",
    "- K-Nearest Neighbours  \n",
    "- Random Forest Classifier  \n",
    "- Decision Tree Classifier  \n",
    "- Support Vector Machine  \n",
    "\n",
    "Metrics → `Accuracy`, `Precision`, `Recall`, `F1`  \n",
    "Visuals → Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c1edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "FEATURES_BASE = Path(\"../data/processed/features2\")\n",
    "PROC_BASE = Path(\"../data/processed/ml2\")\n",
    "MODEL_BASE = Path(\"../models/ml2\")\n",
    "FIG_BASE = Path(\"../figures/ml2\")\n",
    "\n",
    "for p in [PROC_BASE, MODEL_BASE, FIG_BASE]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "METHODS = [\"rfe\",\"skb\",\"fscs\",\"etc\",\"pc\",\"mi\",\"mir\",\"mu\",\"vt\"]\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba050ef",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average=\"weighted\", zero_division=0),\n",
    "        \"F1\": f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    }\n",
    "\n",
    "def save_confusion(y_true, y_pred, path, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_xlabel(\"Predicted\"); ax.set_ylabel(\"True\"); ax.set_title(title)\n",
    "    fig.savefig(path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c8264",
   "metadata": {},
   "source": [
    "## Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a55f7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=RANDOM_STATE),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=RANDOM_STATE),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=RANDOM_STATE),\n",
    "    \"SVM\": SVC(probability=True, random_state=RANDOM_STATE)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155af3e1",
   "metadata": {},
   "source": [
    "## Train All Six Models Across Nine Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d0ac10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Training for feature set: RFE\n",
      " - Logistic Regression\n",
      " - Gradient Boosting\n",
      " - KNN\n",
      " - Random Forest\n",
      " - Decision Tree\n",
      " - SVM\n",
      "Saved metrics to: ..\\data\\processed\\ml2\\rfe\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "Training for feature set: SKB\n",
      " - Logistic Regression\n",
      " - Gradient Boosting\n",
      " - KNN\n",
      " - Random Forest\n",
      " - Decision Tree\n",
      " - SVM\n",
      "Saved metrics to: ..\\data\\processed\\ml2\\skb\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "Training for feature set: FSCS\n",
      " - Logistic Regression\n",
      " - Gradient Boosting\n",
      " - KNN\n",
      " - Random Forest\n",
      " - Decision Tree\n",
      " - SVM\n",
      "Saved metrics to: ..\\data\\processed\\ml2\\fscs\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "Training for feature set: ETC\n",
      " - Logistic Regression\n",
      " - Gradient Boosting\n",
      " - KNN\n",
      " - Random Forest\n",
      " - Decision Tree\n",
      " - SVM\n",
      "Saved metrics to: ..\\data\\processed\\ml2\\etc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "Training for feature set: PC\n",
      " - Logistic Regression\n",
      " - Gradient Boosting\n",
      " - KNN\n",
      " - Random Forest\n",
      " - Decision Tree\n",
      " - SVM\n",
      "Saved metrics to: ..\\data\\processed\\ml2\\pc\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "Training for feature set: MI\n",
      " - Logistic Regression\n",
      " - Gradient Boosting\n",
      " - KNN\n",
      " - Random Forest\n",
      " - Decision Tree\n",
      " - SVM\n",
      "Saved metrics to: ..\\data\\processed\\ml2\\mi\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "Training for feature set: MIR\n",
      " - Logistic Regression\n",
      " - Gradient Boosting\n",
      " - KNN\n",
      " - Random Forest\n",
      " - Decision Tree\n",
      " - SVM\n",
      "Saved metrics to: ..\\data\\processed\\ml2\\mir\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "Training for feature set: MU\n",
      " - Logistic Regression\n",
      " - Gradient Boosting\n",
      " - KNN\n",
      " - Random Forest\n",
      " - Decision Tree\n",
      " - SVM\n",
      "Saved metrics to: ..\\data\\processed\\ml2\\mu\\results_traditional_ml.csv\n",
      "\n",
      "============================================================\n",
      "Training for feature set: VT\n",
      " - Logistic Regression\n",
      " - Gradient Boosting\n",
      " - KNN\n",
      " - Random Forest\n",
      " - Decision Tree\n",
      " - SVM\n",
      "Saved metrics to: ..\\data\\processed\\ml2\\vt\\results_traditional_ml.csv\n"
     ]
    }
   ],
   "source": [
    "for method in METHODS:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Training for feature set: {method.upper()}\")\n",
    "    in_dir = FEATURES_BASE / method\n",
    "    if not in_dir.exists():\n",
    "        print(\"Missing feature folder:\", in_dir); continue\n",
    "\n",
    "    train_df = pd.read_csv(in_dir / \"train.csv\").dropna(subset=[\"DepressionEncoded\"])\n",
    "    test_df = pd.read_csv(in_dir / \"test.csv\").dropna(subset=[\"DepressionEncoded\"])\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_train = train_df[\"DepressionEncoded\"].astype(int)\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_test = test_df[\"DepressionEncoded\"].astype(int)\n",
    "\n",
    "    results = []\n",
    "    proc_out = PROC_BASE / method; model_out = MODEL_BASE / method; fig_out = FIG_BASE / method\n",
    "    for p in [proc_out, model_out, fig_out]: p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for name, model in MODELS.items():\n",
    "        print(\" -\", name)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        metrics = compute_metrics(y_test, y_pred)\n",
    "        results.append({\"Model\": name, **metrics})\n",
    "\n",
    "        # save confusion and model\n",
    "        save_confusion(y_test, y_pred, fig_out / f\"{name.lower().replace(' ','_')}_confusion.png\", f\"{name} Confusion ({method})\")\n",
    "        joblib.dump(model, model_out / f\"{name.lower().replace(' ','_')}.pkl\")\n",
    "\n",
    "    pd.DataFrame(results).to_csv(proc_out / \"results_traditional_ml.csv\", index=False)\n",
    "    print(\"Saved metrics to:\", proc_out / \"results_traditional_ml.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831a2308",
   "metadata": {},
   "source": [
    "## Summary of Model Performance Across All Feature Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207b3fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Feature Set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>0.870920</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>0.868595</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.855699</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.854574</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.845512</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.844046</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.838447</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.837135</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.787300</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.784895</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.725926</td>\n",
       "      <td>0.720429</td>\n",
       "      <td>0.725926</td>\n",
       "      <td>0.720491</td>\n",
       "      <td>ETC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>0.872062</td>\n",
       "      <td>0.869136</td>\n",
       "      <td>0.869049</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.847400</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.844418</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.831728</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.826697</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.823659</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.821978</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.802037</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.799327</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.720227</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.718326</td>\n",
       "      <td>FSCS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.882862</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.881016</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.856129</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.854573</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.839291</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.837031</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.826375</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.824565</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.800256</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.796582</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.699695</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.700423</td>\n",
       "      <td>MI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.874222</td>\n",
       "      <td>0.874074</td>\n",
       "      <td>0.873816</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.859942</td>\n",
       "      <td>0.859259</td>\n",
       "      <td>0.859288</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.857717</td>\n",
       "      <td>0.856790</td>\n",
       "      <td>0.857137</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.812346</td>\n",
       "      <td>0.812884</td>\n",
       "      <td>0.812346</td>\n",
       "      <td>0.812512</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.782841</td>\n",
       "      <td>0.782716</td>\n",
       "      <td>0.782204</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.701235</td>\n",
       "      <td>0.699349</td>\n",
       "      <td>0.701235</td>\n",
       "      <td>0.699705</td>\n",
       "      <td>MIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.839144</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.835547</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.809877</td>\n",
       "      <td>0.812493</td>\n",
       "      <td>0.809877</td>\n",
       "      <td>0.810805</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.809877</td>\n",
       "      <td>0.811380</td>\n",
       "      <td>0.809877</td>\n",
       "      <td>0.810123</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.796819</td>\n",
       "      <td>0.792593</td>\n",
       "      <td>0.793569</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.740592</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.738832</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.693827</td>\n",
       "      <td>0.695152</td>\n",
       "      <td>0.693827</td>\n",
       "      <td>0.694285</td>\n",
       "      <td>MU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866581</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.866312</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.852249</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.851935</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.832099</td>\n",
       "      <td>0.833124</td>\n",
       "      <td>0.832099</td>\n",
       "      <td>0.832434</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.802171</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800492</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.774303</td>\n",
       "      <td>0.775309</td>\n",
       "      <td>0.773804</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.693827</td>\n",
       "      <td>0.696229</td>\n",
       "      <td>0.693827</td>\n",
       "      <td>0.692805</td>\n",
       "      <td>PC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.838375</td>\n",
       "      <td>0.837037</td>\n",
       "      <td>0.837518</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.832099</td>\n",
       "      <td>0.835378</td>\n",
       "      <td>0.832099</td>\n",
       "      <td>0.832702</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.825771</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.823157</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.812346</td>\n",
       "      <td>0.816869</td>\n",
       "      <td>0.812346</td>\n",
       "      <td>0.813583</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>0.797961</td>\n",
       "      <td>0.795062</td>\n",
       "      <td>0.794687</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.716411</td>\n",
       "      <td>0.718519</td>\n",
       "      <td>0.716900</td>\n",
       "      <td>RFE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.882862</td>\n",
       "      <td>0.881481</td>\n",
       "      <td>0.881016</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.856129</td>\n",
       "      <td>0.854321</td>\n",
       "      <td>0.854573</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.829873</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.825867</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.826375</td>\n",
       "      <td>0.824691</td>\n",
       "      <td>0.824565</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.800256</td>\n",
       "      <td>0.797531</td>\n",
       "      <td>0.796582</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.708642</td>\n",
       "      <td>0.703545</td>\n",
       "      <td>0.708642</td>\n",
       "      <td>0.704791</td>\n",
       "      <td>SKB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.866671</td>\n",
       "      <td>0.864198</td>\n",
       "      <td>0.864172</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.841975</td>\n",
       "      <td>0.844430</td>\n",
       "      <td>0.841975</td>\n",
       "      <td>0.841871</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.819753</td>\n",
       "      <td>0.821591</td>\n",
       "      <td>0.819753</td>\n",
       "      <td>0.819652</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.816959</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.814239</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.809499</td>\n",
       "      <td>0.807407</td>\n",
       "      <td>0.806382</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.740826</td>\n",
       "      <td>0.738272</td>\n",
       "      <td>0.738146</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Accuracy  Precision    Recall        F1 Feature Set\n",
       "18  Logistic Regression  0.869136   0.870920  0.869136  0.868595         ETC\n",
       "23                  SVM  0.854321   0.855699  0.854321  0.854574         ETC\n",
       "21        Random Forest  0.844444   0.845512  0.844444  0.844046         ETC\n",
       "19    Gradient Boosting  0.837037   0.838447  0.837037  0.837135         ETC\n",
       "20                  KNN  0.785185   0.787300  0.785185  0.784895         ETC\n",
       "22        Decision Tree  0.725926   0.720429  0.725926  0.720491         ETC\n",
       "12  Logistic Regression  0.869136   0.872062  0.869136  0.869049        FSCS\n",
       "17                  SVM  0.844444   0.847400  0.844444  0.844418        FSCS\n",
       "13    Gradient Boosting  0.827160   0.831728  0.827160  0.826697        FSCS\n",
       "15        Random Forest  0.822222   0.823659  0.822222  0.821978        FSCS\n",
       "14                  KNN  0.800000   0.802037  0.800000  0.799327        FSCS\n",
       "16        Decision Tree  0.718519   0.720227  0.718519  0.718326        FSCS\n",
       "30  Logistic Regression  0.881481   0.882862  0.881481  0.881016          MI\n",
       "35                  SVM  0.854321   0.856129  0.854321  0.854573          MI\n",
       "33        Random Forest  0.837037   0.839291  0.837037  0.837031          MI\n",
       "31    Gradient Boosting  0.824691   0.826375  0.824691  0.824565          MI\n",
       "32                  KNN  0.797531   0.800256  0.797531  0.796582          MI\n",
       "34        Decision Tree  0.703704   0.699695  0.703704  0.700423          MI\n",
       "36  Logistic Regression  0.874074   0.874222  0.874074  0.873816         MIR\n",
       "41                  SVM  0.859259   0.859942  0.859259  0.859288         MIR\n",
       "37    Gradient Boosting  0.856790   0.857717  0.856790  0.857137         MIR\n",
       "39        Random Forest  0.812346   0.812884  0.812346  0.812512         MIR\n",
       "38                  KNN  0.782716   0.782841  0.782716  0.782204         MIR\n",
       "40        Decision Tree  0.701235   0.699349  0.701235  0.699705         MIR\n",
       "42  Logistic Regression  0.837037   0.839144  0.837037  0.835547          MU\n",
       "43    Gradient Boosting  0.809877   0.812493  0.809877  0.810805          MU\n",
       "47                  SVM  0.809877   0.811380  0.809877  0.810123          MU\n",
       "45        Random Forest  0.792593   0.796819  0.792593  0.793569          MU\n",
       "44                  KNN  0.740741   0.740592  0.740741  0.738832          MU\n",
       "46        Decision Tree  0.693827   0.695152  0.693827  0.694285          MU\n",
       "24  Logistic Regression  0.866667   0.866581  0.866667  0.866312          PC\n",
       "29                  SVM  0.851852   0.852249  0.851852  0.851935          PC\n",
       "25    Gradient Boosting  0.832099   0.833124  0.832099  0.832434          PC\n",
       "27        Random Forest  0.800000   0.802171  0.800000  0.800492          PC\n",
       "26                  KNN  0.775309   0.774303  0.775309  0.773804          PC\n",
       "28        Decision Tree  0.693827   0.696229  0.693827  0.692805          PC\n",
       "0   Logistic Regression  0.837037   0.838375  0.837037  0.837518         RFE\n",
       "5                   SVM  0.832099   0.835378  0.832099  0.832702         RFE\n",
       "1     Gradient Boosting  0.822222   0.825771  0.822222  0.823157         RFE\n",
       "3         Random Forest  0.812346   0.816869  0.812346  0.813583         RFE\n",
       "2                   KNN  0.795062   0.797961  0.795062  0.794687         RFE\n",
       "4         Decision Tree  0.718519   0.716411  0.718519  0.716900         RFE\n",
       "6   Logistic Regression  0.881481   0.882862  0.881481  0.881016         SKB\n",
       "11                  SVM  0.854321   0.856129  0.854321  0.854573         SKB\n",
       "9         Random Forest  0.827160   0.829873  0.827160  0.825867         SKB\n",
       "7     Gradient Boosting  0.824691   0.826375  0.824691  0.824565         SKB\n",
       "8                   KNN  0.797531   0.800256  0.797531  0.796582         SKB\n",
       "10        Decision Tree  0.708642   0.703545  0.708642  0.704791         SKB\n",
       "48  Logistic Regression  0.864198   0.866671  0.864198  0.864172          VT\n",
       "53                  SVM  0.841975   0.844430  0.841975  0.841871          VT\n",
       "49    Gradient Boosting  0.819753   0.821591  0.819753  0.819652          VT\n",
       "51        Random Forest  0.814815   0.816959  0.814815  0.814239          VT\n",
       "50                  KNN  0.807407   0.809499  0.807407  0.806382          VT\n",
       "52        Decision Tree  0.738272   0.740826  0.738272  0.738146          VT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved combined summary: ..\\data\\processed\\ml2\\all_model_results_summary_v3.csv\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "for method in METHODS:\n",
    "    res_path = PROC_BASE / method / \"results_traditional_ml.csv\"\n",
    "    if res_path.exists():\n",
    "        df = pd.read_csv(res_path); df[\"Feature Set\"] = method.upper(); all_results.append(df)\n",
    "    else:\n",
    "        print(\"Missing:\", method)\n",
    "if all_results:\n",
    "    combined = pd.concat(all_results, ignore_index=True).sort_values([\"Feature Set\",\"Accuracy\"], ascending=[True,False])\n",
    "    display(combined)\n",
    "    combined.to_csv(PROC_BASE / \"all_model_results_summary_v3.csv\", index=False)\n",
    "    print(\"Saved combined summary:\", PROC_BASE / \"all_model_results_summary_v3.csv\")\n",
    "else:\n",
    "    print(\"No results found.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
