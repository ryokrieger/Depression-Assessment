{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7df389",
   "metadata": {},
   "source": [
    "# Model Training (Machine Learning)\n",
    "\n",
    "We train six traditional ML classifiers on nine feature-selection datasets:\n",
    "\n",
    "1. **Recursive Feature Elimination**\n",
    "2. **Select K Best**\n",
    "3. **Fisher Score Chi-Square**\n",
    "4. **Extra Trees Classifier**\n",
    "5. **Pearson Correlation**\n",
    "6. **Mutual Information**\n",
    "7. **Mutual Info Regression**\n",
    "8. **Manual Uniqueness**\n",
    "9. **Variance Threshold**\n",
    "\n",
    "Each dataset trains:\n",
    "- Logistic Regression  \n",
    "- Gradient Boosting Classifier  \n",
    "- K-Nearest Neighbours  \n",
    "- Random Forest Classifier  \n",
    "- Decision Tree Classifier  \n",
    "- Support Vector Machine  \n",
    "\n",
    "Metrics â†’ `Accuracy`, `Precision`, `Recall`, `F1`  \n",
    "Visuals â†’ Confusion Matrices  \n",
    "Results, Models and Figures are saved in respective folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36c1edf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "\n",
    "DATA_DIR = Path(\"../data/processed/features\")\n",
    "PROC_DIR = Path(\"../data/processed\")\n",
    "MODEL_DIR_BASE = Path(\"../models\")\n",
    "FIG_DIR_BASE = Path(\"../figures\")\n",
    "\n",
    "METHODS = [\"rfe\",\"skb\",\"fscs\",\"etc\",\"pc\",\"mi\",\"mir\",\"mu\",\"vt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba050ef",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "These utilities:\n",
    "- Train each model  \n",
    "- Compute metrics (Accuracy, Precision, Recall, F1)  \n",
    "- Plot and save Confusion Matrices  \n",
    "- Save trained models and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "678308cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, X_train, y_train, X_test, y_test, model_name, method):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", ax=ax)\n",
    "    ax.set_title(f\"{model_name} â€” {method.upper()}\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    fig.tight_layout()\n",
    "\n",
    "    fig_dir = FIG_DIR_BASE / method\n",
    "    fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "    fig_path = fig_dir / f\"{model_name.lower().replace(' ', '_')}_confusion.png\"\n",
    "    fig.savefig(fig_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    return {\"Model\": model_name, \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1\": f1}\n",
    "\n",
    "\n",
    "def save_model(model, model_name, method):\n",
    "    model_dir = MODEL_DIR_BASE / method\n",
    "    model_dir.mkdir(parents=True, exist_ok=True)\n",
    "    path = model_dir / f\"{model_name.lower().replace(' ', '_')}.pkl\"\n",
    "    joblib.dump(model, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c8264",
   "metadata": {},
   "source": [
    "## Model Definitions\n",
    "\n",
    "We define six traditional ML models to train on each feature set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a55f7b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": SVC()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155af3e1",
   "metadata": {},
   "source": [
    "## Train All Six Models Across Nine Feature Sets\n",
    "\n",
    "For each feature-selection method:\n",
    "1. Load train/test CSV files  \n",
    "2. Train six models  \n",
    "3. Compute metrics and save results + models + confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0ac10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training models for RFE ===\n",
      "ðŸ§  Training Logistic Regression\n",
      "ðŸ§  Training Gradient Boosting\n",
      "ðŸ§  Training KNN\n",
      "ðŸ§  Training Random Forest\n",
      "ðŸ§  Training Decision Tree\n",
      "ðŸ§  Training SVM\n",
      "âœ… Saved metrics â†’ ..\\data\\processed\\rfe\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for SKB ===\n",
      "ðŸ§  Training Logistic Regression\n",
      "ðŸ§  Training Gradient Boosting\n",
      "ðŸ§  Training KNN\n",
      "ðŸ§  Training Random Forest\n",
      "ðŸ§  Training Decision Tree\n",
      "ðŸ§  Training SVM\n",
      "âœ… Saved metrics â†’ ..\\data\\processed\\skb\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for FSCS ===\n",
      "ðŸ§  Training Logistic Regression\n",
      "ðŸ§  Training Gradient Boosting\n",
      "ðŸ§  Training KNN\n",
      "ðŸ§  Training Random Forest\n",
      "ðŸ§  Training Decision Tree\n",
      "ðŸ§  Training SVM\n",
      "âœ… Saved metrics â†’ ..\\data\\processed\\fscs\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for ETC ===\n",
      "ðŸ§  Training Logistic Regression\n",
      "ðŸ§  Training Gradient Boosting\n",
      "ðŸ§  Training KNN\n",
      "ðŸ§  Training Random Forest\n",
      "ðŸ§  Training Decision Tree\n",
      "ðŸ§  Training SVM\n",
      "âœ… Saved metrics â†’ ..\\data\\processed\\etc\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for PC ===\n",
      "ðŸ§  Training Logistic Regression\n",
      "ðŸ§  Training Gradient Boosting\n",
      "ðŸ§  Training KNN\n",
      "ðŸ§  Training Random Forest\n",
      "ðŸ§  Training Decision Tree\n",
      "ðŸ§  Training SVM\n",
      "âœ… Saved metrics â†’ ..\\data\\processed\\pc\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for MI ===\n",
      "ðŸ§  Training Logistic Regression\n",
      "ðŸ§  Training Gradient Boosting\n",
      "ðŸ§  Training KNN\n",
      "ðŸ§  Training Random Forest\n",
      "ðŸ§  Training Decision Tree\n",
      "ðŸ§  Training SVM\n",
      "âœ… Saved metrics â†’ ..\\data\\processed\\mi\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for MIR ===\n",
      "ðŸ§  Training Logistic Regression\n",
      "ðŸ§  Training Gradient Boosting\n",
      "ðŸ§  Training KNN\n",
      "ðŸ§  Training Random Forest\n",
      "ðŸ§  Training Decision Tree\n",
      "ðŸ§  Training SVM\n",
      "âœ… Saved metrics â†’ ..\\data\\processed\\mir\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for MU ===\n",
      "ðŸ§  Training Logistic Regression\n",
      "ðŸ§  Training Gradient Boosting\n",
      "ðŸ§  Training KNN\n",
      "ðŸ§  Training Random Forest\n",
      "ðŸ§  Training Decision Tree\n",
      "ðŸ§  Training SVM\n",
      "âœ… Saved metrics â†’ ..\\data\\processed\\mu\\results_traditional_ml.csv\n",
      "\n",
      "=== Training models for VT ===\n",
      "ðŸ§  Training Logistic Regression\n",
      "ðŸ§  Training Gradient Boosting\n",
      "ðŸ§  Training KNN\n",
      "ðŸ§  Training Random Forest\n",
      "ðŸ§  Training Decision Tree\n",
      "ðŸ§  Training SVM\n",
      "âœ… Saved metrics â†’ ..\\data\\processed\\vt\\results_traditional_ml.csv\n"
     ]
    }
   ],
   "source": [
    "for method in METHODS:\n",
    "    print(f\"\\n=== Training models for {method.upper()} ===\")\n",
    "\n",
    "    train_path = DATA_DIR / method / \"train.csv\"\n",
    "    test_path = DATA_DIR / method / \"test.csv\"\n",
    "\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    # Drop any missing rows\n",
    "    train_df = train_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "    test_df = test_df.dropna(subset=[\"DepressionEncoded\"])\n",
    "\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_train = train_df[\"DepressionEncoded\"].astype(int)\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"])\n",
    "    y_test = test_df[\"DepressionEncoded\"].astype(int)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for name, model in MODELS.items():\n",
    "        print(f\"ðŸ§  Training {name}\")\n",
    "        metrics = train_and_evaluate(model, X_train, y_train, X_test, y_test, name, method)\n",
    "        results.append(metrics)\n",
    "        save_model(model, name, method)\n",
    "\n",
    "    res_df = pd.DataFrame(results)\n",
    "    out_dir = PROC_DIR / method\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "    res_df.to_csv(out_dir / \"results_traditional_ml.csv\", index=False)\n",
    "\n",
    "    print(f\"âœ… Saved metrics â†’ {out_dir / 'results_traditional_ml.csv'}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
