{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8029a16",
   "metadata": {},
   "source": [
    "# Model Training (Deep Learning Models)\n",
    "\n",
    "In this notebook, we develop and evaluate two deep learning models:\n",
    "- **Artificial Neural Network (ANN)**\n",
    "- **Convolutional Neural Network (CNN)**\n",
    "\n",
    "Each model is trained and evaluated on:  \n",
    "1Ô∏è‚É£ Feature Set 1 ‚Üí Top 7 from each scale (21 features)  \n",
    "2Ô∏è‚É£ Feature Set 2 ‚Üí All PSS-10 + All PHQ-9 (19 features)  \n",
    "3Ô∏è‚É£ Feature Set 3 ‚Üí All GAD-7 + All PHQ-9 (17 features)\n",
    "\n",
    "For each model and feature set, we show:\n",
    "- Accuracy  \n",
    "- Precision  \n",
    "- Recall  \n",
    "- F1 Score  \n",
    "- Accuracy vs Epoch graph  \n",
    "- Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edac046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import models, layers\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Paths\n",
    "DATA_DIR = Path(\"../data/processed\")\n",
    "MODEL_DIR = Path(\"../models\")\n",
    "FIG_DIR = Path(\"../figures\")\n",
    "\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load feature sets\n",
    "fs1_train = pd.read_csv(DATA_DIR / \"fs1_train.csv\")\n",
    "fs1_test  = pd.read_csv(DATA_DIR / \"fs1_test.csv\")\n",
    "fs2_train = pd.read_csv(DATA_DIR / \"fs2_train.csv\")\n",
    "fs2_test  = pd.read_csv(DATA_DIR / \"fs2_test.csv\")\n",
    "fs3_train = pd.read_csv(DATA_DIR / \"fs3_train.csv\")\n",
    "fs3_test  = pd.read_csv(DATA_DIR / \"fs3_test.csv\")\n",
    "\n",
    "print(\"‚úÖ Feature sets loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a56d4c2",
   "metadata": {},
   "source": [
    "## Helper Functions for Building, Evaluating, and Saving Deep Learning Models\n",
    "\n",
    "Includes:\n",
    "- ANN and CNN architectures  \n",
    "- Evaluation (Accuracy, Precision, Recall, F1, Confusion Matrix)  \n",
    "- Plotting Accuracy vs Epoch  \n",
    "- Saving all outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a8c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_ann(input_dim, num_classes):\n",
    "    \"\"\"Simple feed-forward ANN model.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_dim=input_dim),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_cnn(input_dim, num_classes):\n",
    "    \"\"\"1D CNN adapted for tabular data.\"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Reshape((input_dim, 1), input_shape=(input_dim,)),\n",
    "        layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def evaluate_dl_model(model, X_test, y_test, feature_set_name, model_name):\n",
    "    \"\"\"Evaluate a DL model, compute metrics, and save confusion matrix.\"\"\"\n",
    "    y_pred_prob = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average=\"weighted\", zero_division=0)\n",
    "\n",
    "    # --- Confusion Matrix ---\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    fig, ax = plt.subplots(figsize=(5, 4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_xlabel(\"Predicted Label\")\n",
    "    ax.set_ylabel(\"True Label\")\n",
    "    ax.set_title(f\"Confusion Matrix ‚Äî {model_name} ({feature_set_name})\")\n",
    "    fig_path = FIG_DIR / f\"confusion_{feature_set_name.lower()}_{model_name.lower().replace(' ', '_')}.png\"\n",
    "    fig.savefig(fig_path, bbox_inches=\"tight\", dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"üñºÔ∏è Saved confusion matrix: {fig_path}\")\n",
    "\n",
    "    print(f\"\\nüìä {model_name} ({feature_set_name}) Performance:\")\n",
    "    print(f\"Accuracy: {acc:.4f}, Precision: {prec:.4f}, Recall: {rec:.4f}, F1 Score: {f1:.4f}\")\n",
    "\n",
    "    return {\"Model\": model_name, \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1 Score\": f1}\n",
    "\n",
    "\n",
    "def plot_accuracy(history, feature_set_name, model_name):\n",
    "    \"\"\"Plot and save Accuracy vs Epoch.\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    ax.plot(history.history[\"accuracy\"], label=\"Train Accuracy\")\n",
    "    ax.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "    ax.set_title(f\"Accuracy vs Epoch ‚Äî {model_name} ({feature_set_name})\")\n",
    "    ax.set_xlabel(\"Epochs\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.legend()\n",
    "    fig_path = FIG_DIR / f\"accuracy_{feature_set_name.lower()}_{model_name.lower().replace(' ', '_')}.png\"\n",
    "    fig.savefig(fig_path, bbox_inches=\"tight\", dpi=300)\n",
    "    plt.close(fig)\n",
    "    print(f\"üìà Saved accuracy vs epoch plot: {fig_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87cab99",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation Function for ANN and CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fbd0c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dl_models(fs_name, train_df, test_df, epochs=50, batch_size=32):\n",
    "    \"\"\"Train and evaluate ANN & CNN on a given feature set.\"\"\"\n",
    "    X_train = train_df.drop(columns=[\"DepressionEncoded\"]).values\n",
    "    y_train = to_categorical(train_df[\"DepressionEncoded\"])\n",
    "    X_test = test_df.drop(columns=[\"DepressionEncoded\"]).values\n",
    "    y_test = to_categorical(test_df[\"DepressionEncoded\"])\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    num_classes = y_train.shape[1]\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # ---- ANN ----\n",
    "    print(f\"\\nüß† Training ANN on {fs_name} ...\")\n",
    "    ann = build_ann(input_dim, num_classes)\n",
    "    history_ann = ann.fit(X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    results.append(evaluate_dl_model(ann, X_test, y_test, fs_name, \"ANN\"))\n",
    "    plot_accuracy(history_ann, fs_name, \"ANN\")\n",
    "    ann.save(MODEL_DIR / f\"{fs_name.lower()}_ann_model.h5\")\n",
    "    print(f\"üíæ Saved ANN model for {fs_name}\")\n",
    "\n",
    "    # ---- CNN ----\n",
    "    print(f\"\\nüß© Training CNN on {fs_name} ...\")\n",
    "    cnn = build_cnn(input_dim, num_classes)\n",
    "    history_cnn = cnn.fit(X_train, y_train, validation_split=0.2, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "    results.append(evaluate_dl_model(cnn, X_test, y_test, fs_name, \"CNN\"))\n",
    "    plot_accuracy(history_cnn, fs_name, \"CNN\")\n",
    "    cnn.save(MODEL_DIR / f\"{fs_name.lower()}_cnn_model.h5\")\n",
    "    print(f\"üíæ Saved CNN model for {fs_name}\")\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbb33c2",
   "metadata": {},
   "source": [
    "## Feature Set 1 ‚Äî Deep Learning Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35ccc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dl_fs1 = train_dl_models(\"FS1\", fs1_train, fs1_test)\n",
    "display(results_dl_fs1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b39451",
   "metadata": {},
   "source": [
    "## Feature Set 2 ‚Äî Deep Learning Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d513fdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dl_fs2 = train_dl_models(\"FS2\", fs2_train, fs2_test)\n",
    "display(results_dl_fs2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6299e1",
   "metadata": {},
   "source": [
    "## Feature Set 3 ‚Äî Deep Learning Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ad146",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dl_fs3 = train_dl_models(\"FS3\", fs3_train, fs3_test)\n",
    "display(results_dl_fs3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a17eb7",
   "metadata": {},
   "source": [
    "## Save Deep Learning Model Results\n",
    "All evaluation tables are saved for future comparison with traditional ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a91b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dl_fs1.to_csv(DATA_DIR / \"results_fs1_deep_learning.csv\", index=False)\n",
    "results_dl_fs2.to_csv(DATA_DIR / \"results_fs2_deep_learning.csv\", index=False)\n",
    "results_dl_fs3.to_csv(DATA_DIR / \"results_fs3_deep_learning.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Saved Deep Learning results to data/processed/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
