{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb9e8740",
   "metadata": {},
   "source": [
    "# Step 4 ‚Äî Feature Engineering\n",
    "\n",
    "In this notebook we create **9 feature sets** from the processed dataset.\n",
    "\n",
    "Each method selects the **top 5 features from each scale** (PSS-10, GAD-7, PHQ-9) ‚Üí 15 features total.\n",
    "\n",
    "We then split the data (80/20, stratified) for model training later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fceb834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import (\n",
    "    RFE, SelectKBest, chi2, mutual_info_classif, mutual_info_regression, VarianceThreshold\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Base paths\n",
    "DATA_PATH = Path(\"../data/processed/mhp_processed.csv\")\n",
    "OUT_BASE = Path(\"../data/processed/features\")\n",
    "OUT_BASE.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f815c636",
   "metadata": {},
   "source": [
    "## Load and prepare the dataset\n",
    "We load `mhp_processed.csv`, encode `Depression Label` ‚Üí `DepressionEncoded`,  \n",
    "and identify columns by scale: PSS, GAD, PHQ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345405b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSS cols: 10, GAD cols: 7, PHQ cols: 9\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "# Encode Depression Label\n",
    "label_map = {\n",
    "    \"Minimal\": 0, \"Mild\": 1, \"Moderate\": 2,\n",
    "    \"Moderately Severe\": 3, \"Severe\": 4\n",
    "}\n",
    "df[\"DepressionEncoded\"] = df[\"Depression Label\"].map(label_map)\n",
    "\n",
    "# Fill NaNs by recomputing from PHQ-9 if missing\n",
    "phq_cols = [c for c in df.columns if c.startswith(\"PHQ\")]\n",
    "phq_sum = df[phq_cols].sum(axis=1)\n",
    "df.loc[df[\"DepressionEncoded\"].isna(), \"DepressionEncoded\"] = pd.cut(\n",
    "    phq_sum,\n",
    "    bins=[-1, 4, 9, 14, 19, 27],\n",
    "    labels=[0, 1, 2, 3, 4]\n",
    ").astype(int)\n",
    "\n",
    "df[\"DepressionEncoded\"] = df[\"DepressionEncoded\"].astype(int)\n",
    "\n",
    "# Identify scale columns\n",
    "pss_cols = [c for c in df.columns if c.startswith(\"PSS\")]\n",
    "gad_cols = [c for c in df.columns if c.startswith(\"GAD\")]\n",
    "phq_cols = [c for c in df.columns if c.startswith(\"PHQ\")]\n",
    "\n",
    "print(f\"PSS cols: {len(pss_cols)}, GAD cols: {len(gad_cols)}, PHQ cols: {len(phq_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78536844",
   "metadata": {},
   "source": [
    "## Feature Selection Helpers\n",
    "\n",
    "Each function returns the top N features for a given scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "958fbff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_rfe(X, y, n=5):\n",
    "    model = LogisticRegression(max_iter=500)\n",
    "    selector = RFE(model, n_features_to_select=n)\n",
    "    selector.fit(X, y)\n",
    "    return X.columns[selector.support_].tolist()\n",
    "\n",
    "def select_skb(X, y, n=5):\n",
    "    skb = SelectKBest(score_func=f_classif, k=n)\n",
    "    skb.fit(X, y)\n",
    "    return X.columns[skb.get_support()].tolist()\n",
    "\n",
    "def select_fscs(X, y, n=5):\n",
    "    # Fisher Score (Chi2)\n",
    "    Xn = X - X.min()  # chi2 requires non-negative\n",
    "    fs = SelectKBest(score_func=chi2, k=n)\n",
    "    fs.fit(Xn, y)\n",
    "    return X.columns[fs.get_support()].tolist()\n",
    "\n",
    "def select_etc(X, y, n=5):\n",
    "    model = ExtraTreesClassifier(random_state=42)\n",
    "    model.fit(X, y)\n",
    "    imp = pd.Series(model.feature_importances_, index=X.columns)\n",
    "    return imp.nlargest(n).index.tolist()\n",
    "\n",
    "def select_pc(X, y, n=5):\n",
    "    corrs = X.corrwith(y).abs().sort_values(ascending=False)\n",
    "    return corrs.head(n).index.tolist()\n",
    "\n",
    "def select_mi(X, y, n=5):\n",
    "    mi = mutual_info_classif(X, y, random_state=42)\n",
    "    return X.columns[np.argsort(mi)[-n:]].tolist()\n",
    "\n",
    "def select_mir(X, y, n=5):\n",
    "    mir = mutual_info_regression(X, y, random_state=42)\n",
    "    return X.columns[np.argsort(mir)[-n:]].tolist()\n",
    "\n",
    "def select_mu(X, y, n=5):\n",
    "    uniq = X.nunique().sort_values(ascending=False)\n",
    "    return uniq.head(n).index.tolist()\n",
    "\n",
    "def select_vt(X, y, n=5):\n",
    "    vt = VarianceThreshold()\n",
    "    vt.fit(X)\n",
    "    var = pd.Series(vt.variances_, index=X.columns)\n",
    "    return var.nlargest(n).index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be915054",
   "metadata": {},
   "source": [
    "## Run all nine feature selection methods\n",
    "\n",
    "Each method selects 5 features per scale, combines them into 15 features, scales them, splits 80/20 (stratified), and saves train/test CSVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38efa603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üèóÔ∏è Feature Selection: RFE\n",
      "‚úÖ Saved feature set for RFE (15 features)\n",
      "\n",
      "üèóÔ∏è Feature Selection: SKB\n",
      "‚úÖ Saved feature set for SKB (15 features)\n",
      "\n",
      "üèóÔ∏è Feature Selection: FSCS\n",
      "‚úÖ Saved feature set for FSCS (15 features)\n",
      "\n",
      "üèóÔ∏è Feature Selection: ETC\n",
      "‚úÖ Saved feature set for ETC (15 features)\n",
      "\n",
      "üèóÔ∏è Feature Selection: PC\n",
      "‚úÖ Saved feature set for PC (15 features)\n",
      "\n",
      "üèóÔ∏è Feature Selection: MI\n",
      "‚úÖ Saved feature set for MI (15 features)\n",
      "\n",
      "üèóÔ∏è Feature Selection: MIR\n",
      "‚úÖ Saved feature set for MIR (15 features)\n",
      "\n",
      "üèóÔ∏è Feature Selection: MU\n",
      "‚úÖ Saved feature set for MU (15 features)\n",
      "\n",
      "üèóÔ∏è Feature Selection: VT\n",
      "‚úÖ Saved feature set for VT (15 features)\n"
     ]
    }
   ],
   "source": [
    "methods = {\n",
    "    \"rfe\": select_rfe,\n",
    "    \"skb\": select_skb,\n",
    "    \"fscs\": select_fscs,\n",
    "    \"etc\": select_etc,\n",
    "    \"pc\": select_pc,\n",
    "    \"mi\": select_mi,\n",
    "    \"mir\": select_mir,\n",
    "    \"mu\": select_mu,\n",
    "    \"vt\": select_vt\n",
    "}\n",
    "\n",
    "summary = []\n",
    "\n",
    "X = df[pss_cols + gad_cols + phq_cols]\n",
    "y = df[\"DepressionEncoded\"]\n",
    "\n",
    "for name, func in methods.items():\n",
    "    print(f\"\\nüèóÔ∏è Feature Selection: {name.upper()}\")\n",
    "\n",
    "    selected = []\n",
    "    for scale in [pss_cols, gad_cols, phq_cols]:\n",
    "        sel = func(df[scale], y, n=5)\n",
    "        selected.extend(sel)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_sel = scaler.fit_transform(X[selected])\n",
    "    X_sel = pd.DataFrame(X_sel, columns=selected)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_sel, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    out_dir = OUT_BASE / name\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    train_df = X_train.copy()\n",
    "    train_df[\"DepressionEncoded\"] = y_train.values\n",
    "    test_df = X_test.copy()\n",
    "    test_df[\"DepressionEncoded\"] = y_test.values\n",
    "\n",
    "    train_df.to_csv(out_dir / \"train.csv\", index=False)\n",
    "    test_df.to_csv(out_dir / \"test.csv\", index=False)\n",
    "\n",
    "    summary.append({\"Method\": name, \"Selected Features\": selected})\n",
    "    print(f\"‚úÖ Saved feature set for {name.upper()} ({len(selected)} features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d42c59c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÑ Saved feature_selection_summary.csv\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame(summary).to_csv(\"../data/processed/feature_selection_summary.csv\", index=False)\n",
    "print(\"üìÑ Saved feature_selection_summary.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
